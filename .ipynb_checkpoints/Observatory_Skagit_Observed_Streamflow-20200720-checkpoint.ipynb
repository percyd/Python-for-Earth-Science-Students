{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# A Notebook to acquire the latest USGS Streamlow data \n",
    "<br /><br />\n",
    "\n",
    "*Use this Jupyter Notebook to:* <br /> \n",
    "Download USGS streamflow<br />\n",
    "Calculate daily, monthly, and annual streamflow observed data. <br /> \n",
    "Save results back to HydroShare. <br /> \n",
    " <br /> <br /> <img src=\"https://www.washington.edu/brand/files/2014/09/W-Logo_Purple_Hex.png\" style=\"float:right;width:120px;padding:20px\">  \n",
    "#### Civil and Environmental Engineering Department at the University of Washington "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  HydroShare Setup and Preparation\n",
    "\n",
    "To run this notebook, we must import several libaries. These are listed in order of 1) Python standard libraries, 2) hs_utils library provides functions for interacting with HydroShare, including resource querying, dowloading and creation, and 3) the observatory_gridded_hydromet library that is downloaded with this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Python libraries available on CUAHSI JupyterHub \n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#HydroShare Utilities\n",
    "#from utilities import hydroshare\n",
    "#hs = hydroshare.hydroshare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download USGS Daily and Instantaneous Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ulmo\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/6b/fdb27ffe9dfd6d1fe73b33e3e2db7bf35faebc0f50c35836d5fc09e311b7/ulmo-0.8.5-py2.py3-none-any.whl (83kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 4.8MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.7/site-packages (from ulmo) (4.8.1)\n",
      "Collecting geojson\n",
      "  Downloading https://files.pythonhosted.org/packages/e4/8d/9e28e9af95739e6d2d2f8d4bef0b3432da40b7c3588fbad4298c1be09e48/geojson-2.5.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from ulmo) (1.17.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from ulmo) (2.22.0)\n",
      "Collecting html5lib<=0.9999999\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/ae/bcb60402c60932b32dfaf19bb53870b29eda2cd17551ba5639219fb5ebf9/html5lib-0.9999999.tar.gz (889kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 12.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting suds-jurko\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/6f/54fbf0999a606680d27c69b1ad12dfff62768ecb9fe48524cebda6eb4423/suds-jurko-0.6.tar.bz2 (143kB)\n",
      "\u001b[K     |████████████████████████████████| 153kB 25.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting future\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
      "\u001b[K     |████████████████████████████████| 829kB 23.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting lxml\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/3c/fa420469c0d4f62ae39f19ee6505f90d00ae469f6264f4f54e61ed9d9a2c/lxml-4.5.2-cp37-cp37m-manylinux1_x86_64.whl (5.5MB)\n",
      "\u001b[K     |████████████████████████████████| 5.5MB 23.5MB/s eta 0:00:01B 23.5MB/s eta 0:00:01�██████████████████▎      | 4.4MB 23.5MB/s eta 0:00:013MB 23.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting appdirs\n",
      "  Using cached https://files.pythonhosted.org/packages/3b/00/2344469e2084fb287c2e0b57b72910309874c3245463acd6cf5e3db69324/appdirs-1.4.4-py2.py3-none-any.whl\n",
      "Collecting tables\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/cb/4097be890a773af95343389faa8c283b0d9ff606f144227a548461dcbdd5/tables-3.6.1-cp37-cp37m-manylinux1_x86_64.whl (4.3MB)\n",
      "\u001b[K     |████████████████████████████████| 4.3MB 26.5MB/s eta 0:00:01�██                            | 532kB 26.5MB/s eta 0:00:01�████████▌  | 4.0MB 26.5MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from ulmo) (0.25.3)\n",
      "Collecting isodate\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 7.0MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: soupsieve>=1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4->ulmo) (1.9.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->ulmo) (2020.4.5.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->ulmo) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->ulmo) (1.25.6)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->ulmo) (2.8)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from html5lib<=0.9999999->ulmo) (1.13.0)\n",
      "Requirement already satisfied: numexpr>=2.6.2 in /opt/conda/lib/python3.7/site-packages (from tables->ulmo) (2.6.9)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from pandas->ulmo) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas->ulmo) (2019.3)\n",
      "Building wheels for collected packages: html5lib, suds-jurko, future\n",
      "  Building wheel for html5lib (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for html5lib: filename=html5lib-0.9999999-cp37-none-any.whl size=107221 sha256=a81d47658e6f7ef73826fabfe26e4a0722793a2e2e29ea373b43318c9ed12a98\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/50/ae/f9/d2b189788efcf61d1ee0e36045476735c838898eef1cad6e29\n",
      "  Building wheel for suds-jurko (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for suds-jurko: filename=suds_jurko-0.6-cp37-none-any.whl size=454299 sha256=ac84f1d403bd7b13d058e454b42c60ad42733c1dcc1a7081df2f21d3219f65e8\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/12/68/53/d3902c054e32115da1d45bac442a547a071a86a65db4d77027\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.2-cp37-none-any.whl size=491057 sha256=aabc1a8d401ccccd1dda3bf246374f224e9705013f286e5491f39121f58a17f3\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
      "Successfully built html5lib suds-jurko future\n",
      "Installing collected packages: geojson, html5lib, suds-jurko, future, lxml, appdirs, tables, isodate, ulmo\n",
      "Successfully installed appdirs-1.4.4 future-0.18.2 geojson-2.5.0 html5lib-0.9999999 isodate-0.6.0 lxml-4.5.2 suds-jurko-0.6 tables-3.6.1 ulmo-0.8.5\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install ulmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ulmo\n",
    "import json\n",
    "from ulmo.usgs import nwis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get metadata for a list of stations and save to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "making request for sites: http://waterservices.usgs.gov/nwis/dv/\n",
      "processing data from request: https://waterservices.usgs.gov/nwis/dv/?format=waterml&sites=12189500%2C12186000\n",
      "making request for sites: http://waterservices.usgs.gov/nwis/iv/\n",
      "processing data from request: https://waterservices.usgs.gov/nwis/iv/?format=waterml&sites=12189500%2C12186000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'12186000': {'code': '12186000', 'name': 'SAUK RIVER AB WHITE CHUCK RIVER NR  DARRINGTON, WA', 'network': 'NWIS', 'agency': 'USGS', 'location': {'latitude': '48.16872009', 'longitude': '-121.4706723', 'srs': 'EPSG:4326'}, 'timezone_info': {'uses_dst': True, 'dst_tz': {'abbreviation': 'PDT', 'offset': '-07:00'}, 'default_tz': {'abbreviation': 'PST', 'offset': '-08:00'}}, 'county': '53061', 'huc': '17110006', 'site_type': 'ST', 'state_code': '53'}, '12189500': {'code': '12189500', 'name': 'SAUK RIVER NEAR SAUK, WA', 'network': 'NWIS', 'agency': 'USGS', 'location': {'latitude': '48.42455859', 'longitude': '-121.5684634', 'srs': 'EPSG:4326'}, 'timezone_info': {'uses_dst': True, 'dst_tz': {'abbreviation': 'PDT', 'offset': '-07:00'}, 'default_tz': {'abbreviation': 'PST', 'offset': '-08:00'}}, 'county': '53057', 'huc': '17110006', 'site_type': 'ST', 'state_code': '53'}}\n"
     ]
    }
   ],
   "source": [
    "insta_metadata=ulmo.usgs.nwis.get_sites(sites={'12186000','12189500'})\n",
    "print(insta_metadata)\n",
    "\n",
    "with open('Sauk_USGS_15min_meta.json', 'w') as f:\n",
    "    f.write(json.dumps(insta_metadata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get 'instantaneous' or 15-min data for two storms of interest at two locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing data from request: https://nwis.waterservices.usgs.gov/nwis/iv/?format=waterml&site=12189500&startDT=2006-10-01T00%3A00%3A00&endDT=2006-11-30T00%3A00%3A00\n"
     ]
    }
   ],
   "source": [
    "#Sauk River near Sauk 2006 flood\n",
    "data=ulmo.usgs.nwis.get_site_data('12189500',service='instantaneous',start='10/01/2006',end='11/30/2006')\n",
    "df = pd.DataFrame(data['00060:00000']['values']).drop(['qualifiers'], axis=1).set_index('datetime')\n",
    "df.value = df.value.apply(np.float)\n",
    "#df.index = pd.to_datetime(df.index).to_period('min')\n",
    "# mark bad data as NaN\n",
    "df[df.values == -999999] = np.nan\n",
    "df.to_csv('12189500_usgs_15min2006.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing data from request: https://nwis.waterservices.usgs.gov/nwis/iv/?format=waterml&site=12189500&startDT=2009-10-01T00%3A00%3A00&endDT=2009-11-30T00%3A00%3A00\n"
     ]
    }
   ],
   "source": [
    "#Sauk River near Sauk 2009 flood\n",
    "data=ulmo.usgs.nwis.get_site_data('12189500',service='instantaneous',start='10/01/2009',end='11/30/2009')\n",
    "df = pd.DataFrame(data['00060:00000']['values']).drop(['qualifiers'], axis=1).set_index('datetime')\n",
    "df.value = df.value.apply(np.float)\n",
    "#df.index = pd.to_datetime(df.index).to_period('min')\n",
    "# mark bad data as NaN\n",
    "df[df.values == -999999] = np.nan\n",
    "df.to_csv('12189500_usgs_15min2009.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing data from request: https://nwis.waterservices.usgs.gov/nwis/iv/?format=waterml&site=12186000&startDT=2006-10-01T00%3A00%3A00&endDT=2006-11-30T00%3A00%3A00\n"
     ]
    }
   ],
   "source": [
    "#Sauk above White Chuck 2006 flood\n",
    "data=ulmo.usgs.nwis.get_site_data('12186000',service='instantaneous',start='10/01/2006',end='11/30/2006')\n",
    "df = pd.DataFrame(data['00060:00000']['values']).drop(['qualifiers'], axis=1).set_index('datetime')\n",
    "df.value = df.value.apply(np.float)\n",
    "#df.index = pd.to_datetime(df.index).to_period('min')\n",
    "# mark bad data as NaN\n",
    "df[df.values == -999999] = np.nan\n",
    "df.to_csv('12186000_usgs_15min2006.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing data from request: https://nwis.waterservices.usgs.gov/nwis/iv/?format=waterml&site=12186000&startDT=2009-10-01T00%3A00%3A00&endDT=2009-11-30T00%3A00%3A00\n"
     ]
    }
   ],
   "source": [
    "#Sauk above White Chuck 2009 flood\n",
    "data=ulmo.usgs.nwis.get_site_data('12186000',service='instantaneous',start='10/01/2009',end='11/30/2009')\n",
    "df = pd.DataFrame(data['00060:00000']['values']).drop(['qualifiers'], axis=1).set_index('datetime')\n",
    "df.value = df.value.apply(np.float)\n",
    "#df.index = pd.to_datetime(df.index).to_period('min')\n",
    "# mark bad data as NaN\n",
    "df[df.values == -999999] = np.nan\n",
    "df.to_csv('12186000_usgs_15min2009.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn more about the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ulmo.usgs.nwis.get_site_data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['00010:00000', '00060:00000', '00065:00000', '63680:00000'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['site', 'variable', 'values', 'methods', 'qualifiers', 'last_refresh'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['00060:00000'].keys()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Daily Streamflow Data for Sauk River near Sauk USGS (12189500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing data from request: https://waterservices.usgs.gov/nwis/dv/?format=waterml&site=12189500&period=11%2F30%2F2010&startDT=2000-10-01\n",
      "processing data from request: https://waterservices.usgs.gov/nwis/dv/?format=waterml&site=12189500&startDT=1851-01-01\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ulmo.usgs import nwis\n",
    "\n",
    "data_10=ulmo.usgs.nwis.get_site_data('12189500',service='daily',start='10/01/2000',period='11/30/2010')\n",
    "data=ulmo.usgs.nwis.get_site_data('12189500',service='daily',period='all')\n",
    "\n",
    "df = pd.DataFrame(data['00060:00003']['values']).drop(['qualifiers'], axis=1).set_index('datetime')\n",
    "\n",
    "# convert data to a pandas dataframe\n",
    "#df = pd.DataFrame(data['values']).drop(['last_checked','last_modified','qualifiers'], axis=1).set_index('datetime')\n",
    "df.value = df.value.apply(np.float)\n",
    "df.index = pd.to_datetime(df.index).to_period('D')\n",
    "\n",
    "\n",
    "# mark bad data as NaN\n",
    "df[df.values == -999999] = np.nan\n",
    "df.to_csv('12189500_usgs_daily.csv')\n",
    "\n",
    "# download and cache site data (this will take a long time the first time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34079, 1)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1911-04-01</th>\n",
       "      <td>3380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911-04-02</th>\n",
       "      <td>3110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911-04-03</th>\n",
       "      <td>2850.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911-04-04</th>\n",
       "      <td>2590.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911-04-05</th>\n",
       "      <td>2340.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             value\n",
       "datetime          \n",
       "1911-04-01  3380.0\n",
       "1911-04-02  3110.0\n",
       "1911-04-03  2850.0\n",
       "1911-04-04  2590.0\n",
       "1911-04-05  2340.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date']=df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1911-04-01</th>\n",
       "      <td>3380.0</td>\n",
       "      <td>1911-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911-04-02</th>\n",
       "      <td>3110.0</td>\n",
       "      <td>1911-04-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911-04-03</th>\n",
       "      <td>2850.0</td>\n",
       "      <td>1911-04-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911-04-04</th>\n",
       "      <td>2590.0</td>\n",
       "      <td>1911-04-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911-04-05</th>\n",
       "      <td>2340.0</td>\n",
       "      <td>1911-04-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             value        Date\n",
       "datetime                      \n",
       "1911-04-01  3380.0  1911-04-01\n",
       "1911-04-02  3110.0  1911-04-02\n",
       "1911-04-03  2850.0  1911-04-03\n",
       "1911-04-04  2590.0  1911-04-04\n",
       "1911-04-05  2340.0  1911-04-05"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value    4371.179964\n",
      "dtype: float64\n",
      "value    4371.179964\n",
      "dtype: float64\n",
      "value    4370.082071\n",
      "dtype: float64\n",
      "value    4365.454032\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# group the data by month, day & calculate means\n",
    "#daily_groups = df.groupby((lambda Date: Date.month, lambda Date: Date.day))\n",
    "#daily_groups=df.groupby(pd.Grouper(key='Date',freq='M')).mean()\n",
    "daily_groups = df.resample('D').mean()\n",
    "monthly_groups = df.resample('M').mean()\n",
    "annual_groups = df.resample('Y').mean()\n",
    "print(df.mean())\n",
    "print(daily_groups.mean())\n",
    "print(monthly_groups.mean())\n",
    "print(annual_groups.mean())\n",
    "monthly_groups.to_csv('12189500_usgs_monthly.csv')\n",
    "annual_groups.to_csv('12189500_usgs_annual.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1911</th>\n",
       "      <td>4061.236364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1912</th>\n",
       "      <td>4832.605634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1913</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1914</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                value\n",
       "datetime             \n",
       "1911      4061.236364\n",
       "1912      4832.605634\n",
       "1913              NaN\n",
       "1914              NaN\n",
       "1915              NaN"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annual_groups[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1911-04</th>\n",
       "      <td>2685.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911-05</th>\n",
       "      <td>5495.483871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911-06</th>\n",
       "      <td>8516.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911-07</th>\n",
       "      <td>5629.032258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911-08</th>\n",
       "      <td>2362.903226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                value\n",
       "datetime             \n",
       "1911-04   2685.333333\n",
       "1911-05   5495.483871\n",
       "1911-06   8516.333333\n",
       "1911-07   5629.032258\n",
       "1911-08   2362.903226"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_groups[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['00010:00001', '00010:00002', '00010:00003', '00060:00003', '00065:00003', '63680:00008'])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "ronda=data['00060:00003']['values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34079"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.size(ronda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'value': '3380', 'qualifiers': 'A', 'datetime': '1911-04-01T00:00:00'}\n",
      "{'value': '4780', 'qualifiers': 'P', 'datetime': '2020-07-19T00:00:00'}\n"
     ]
    }
   ],
   "source": [
    "print(data['00060:00003']['values'][0])\n",
    "print(data['00060:00003']['values'][np.size(ronda)-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1911-04-01T00:00:00</th>\n",
       "      <td>3380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911-04-02T00:00:00</th>\n",
       "      <td>3110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911-04-03T00:00:00</th>\n",
       "      <td>2850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911-04-04T00:00:00</th>\n",
       "      <td>2590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911-04-05T00:00:00</th>\n",
       "      <td>2340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-15T00:00:00</th>\n",
       "      <td>4230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-16T00:00:00</th>\n",
       "      <td>4980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-17T00:00:00</th>\n",
       "      <td>5260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-18T00:00:00</th>\n",
       "      <td>4820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-19T00:00:00</th>\n",
       "      <td>4780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34079 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    value\n",
       "datetime                 \n",
       "1911-04-01T00:00:00  3380\n",
       "1911-04-02T00:00:00  3110\n",
       "1911-04-03T00:00:00  2850\n",
       "1911-04-04T00:00:00  2590\n",
       "1911-04-05T00:00:00  2340\n",
       "...                   ...\n",
       "2020-07-15T00:00:00  4230\n",
       "2020-07-16T00:00:00  4980\n",
       "2020-07-17T00:00:00  5260\n",
       "2020-07-18T00:00:00  4820\n",
       "2020-07-19T00:00:00  4780\n",
       "\n",
       "[34079 rows x 1 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save the results back into HydroShare\n",
    "<a name=\"creation\"></a>\n",
    "\n",
    "Using the `hs_utils` library, the results of the Geoprocessing steps above can be saved back into HydroShare.  First, define all of the required metadata for resource creation, i.e. *title*, *abstract*, *keywords*, *content files*.  In addition, we must define the type of resource that will be created, in this case *genericresource*.  \n",
    "\n",
    "***Note:*** Make sure you save the notebook at this point, so that all notebook changes will be saved into the new HydroShare resource."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move each file on the server within the 'files' list to an :EXISTING\" HydroShare Generic Resource content folder.  Parent_resource is the destination resource ID for an existing Generic Resource. Files is a list of filepaths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12186000_usgs_15min2006.csv  12189500_usgs_daily.csv\r\n",
      "12186000_usgs_15min2009.csv  12189500_usgs_monthly.csv\r\n",
      "12189500_usgs_15min2006.csv  Observatory_Skagit_Observed_Streamflow.ipynb\r\n",
      "12189500_usgs_15min2009.csv  observedstreamflow.tar\r\n",
      "12189500_usgs_annual.csv     Sauk_USGS_15min_meta.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observedstreamflow/\n",
      "observedstreamflow/12186000_usgs_15min2006.csv\n",
      "observedstreamflow/12186000_usgs_15min2009.csv\n",
      "observedstreamflow/12189500_usgs_15min2006.csv\n",
      "observedstreamflow/12189500_usgs_15min2009.csv\n",
      "observedstreamflow/12189500_usgs_daily.csv\n",
      "observedstreamflow/Sauk_USGS_15min_meta.json\n",
      "observedstreamflow/ogh_meta.json\n",
      "12186000_usgs_15min2006.csv\t  Observatory_Skagit_Observed_Streamflow.ipynb\n",
      "12186000_usgs_15min2009.csv\t  observedstreamflow\n",
      "12189500_usgs_15min2006.csv\t  observedstreamflow.tar\n",
      "12189500_usgs_15min2009.csv\t  ogh_meta.json\n",
      "12189500_usgs_daily.csv\t\t  ogh.py\n",
      "Observatory_Sauk_Climate.ipynb\t  Sauk_USGS_15min_meta.json\n",
      "Observatory_Sauk_Incubator.ipynb\n"
     ]
    }
   ],
   "source": [
    "!mkdir observedstreamflow\n",
    "!cp *.csv observedstreamflow\n",
    "!cp *.json observedstreamflow\n",
    "!tar -cvf observedstreamflow.tar observedstreamflow\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ThisNotebook='Observatory_Skagit_Observed_Streamflow.ipynb' #check name for consistency\n",
    "observedstreamflow='observedstreamflow.tar'\n",
    "\n",
    "\n",
    "files=[ThisNotebook,\n",
    "       observedstreamflow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each file downloaded onto the server folder, move to a new HydroShare Generic Resource\n",
    "title = 'Skagit Observatory download observed daily and instantaneous (15min) streamflow data.'\n",
    "abstract = 'Observed streamflow from Sauk near Sauk (12189500) and Sauk above White Chuck(12186000). This dataset was generated January 16, 2018.'\n",
    "keywords = ['Sauk', 'NWIS', 'USGS','streamflow'] \n",
    "rtype = 'genericresource'  \n",
    "\n",
    "# create the new resource\n",
    "resource_id = hs.createHydroShareResource(abstract, \n",
    "                                          title,\n",
    "                                          keywords=keywords, \n",
    "                                          resource_type=rtype, \n",
    "                                          content_files=files, \n",
    "                                          public=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
